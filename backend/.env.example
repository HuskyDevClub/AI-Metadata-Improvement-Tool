# Python Backend Configuration for AI Metadata Improvement Tool
# Copy this file to .env and fill in your values

# Socrata API Configuration (required)
SOCRATA_APP_TOKEN=

# Default LLM endpoint (optional - can also be set via UI)
# Works with any OpenAI-compatible API (OpenAI, Azure, HuggingFace, etc.)
# Recommended models: gpt5-mini, gpt5-nano, Qwen3-4B-Instruct-2507, Qwen/Qwen3-8B,
#   mistralai/Ministral-3-8B-Instruct-2512, mistralai/Ministral-3-14B-Instruct-2512
AZURE_ENDPOINT=https://your-resource.openai.azure.com/openai/v1/
AZURE_KEY=your-api-key
AZURE_MODEL=gpt5-mini

# Ollama (optional - auto-detects local Ollama, highest priority for local models)
OLLAMA_HOST=http://localhost:11434

# LM Studio (optional - auto-detects local LM Studio, second priority)
LM_STUDIO_URL=http://localhost:1234/v1

# HuggingFace Router (optional - third priority, requires API key)
HF_API_KEY=
HF_API_URL=https://router.huggingface.co/v1

# Server Configuration
PORT=8000
